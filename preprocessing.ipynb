{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import locale\n",
    "from preprocessing_functions import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'da_DK.UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her hentes labelled artikler ind\n",
    "\n",
    "xx = pd.read_feather('data/articles_df_daniel_label.feather')\n",
    "yy = pd.read_feather('data/articles_df_esben_label.feather')\n",
    "\n",
    "articles_df = xx.append(yy)\n",
    "\n",
    "del xx, yy\n",
    "\n",
    "# remove all rows where articles_score is NaN – Keeping all the labelled articles\n",
    "articles_df = articles_df[articles_df['articles_score'].notna()].reset_index(drop=True)\n",
    "\n",
    "stop = (stopwords.words('danish')) # load stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['article_title'].fillna(\"\",inplace=True)\n",
    "articles_df['article_sub_header'].fillna(\"\",inplace=True)\n",
    "articles_df['article_body'].fillna(\"\",inplace=True)\n",
    "\n",
    "# if it is not None set the None to empty string\n",
    "articles_df['article_textbox'].fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the title, subheader and body into one column\n",
    "articles_df['article'] = articles_df['article_title'] + ' ' + articles_df['article_sub_header'] + ' ' + articles_df['article_body'] + articles_df['article_textbox']\n",
    "# articles_df['article_deep'] = articles_df['article_title'] + ' ' + articles_df['article_sub_header'] + ' ' + articles_df['article_body'] + articles_df['article_textbox']\n",
    "\n",
    "articles_df[articles_df['article'].isna()] # Checking if there are any empty articles. There must NOT be any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot of preprocessing of the text \n",
    "\n",
    "# Cleaning html elements\n",
    "articles_df['article'] = articles_df['article'].apply(lambda x: remove_html_elements(x))\n",
    "articles_df['article_bert'] = articles_df['article'].apply(lambda x: remove_html_elements(x)) \n",
    "\n",
    "# Cleaning extra spaces\n",
    "articles_df['article'] = articles_df['article'].apply(lambda x: remove_extra_spaces(x))\n",
    "articles_df['article_bert'] = articles_df['article'].apply(lambda x: remove_extra_spaces(x))\n",
    "\n",
    "# Appending a column with the stopwords count\n",
    "articles_df['stopword_count'] = articles_df['article'].apply(lambda x: stopword_counter(x)) \n",
    "\n",
    "# Appending a column with the punctuation count\n",
    "articles_df['period_count'] = articles_df['article'].apply(lambda x: punctuation_counter(x))\n",
    "\n",
    "# Appending a column with the word count\n",
    "articles_df['word_count'] = articles_df['article'].apply(lambda x: word_counter(x))\n",
    "\n",
    "# Appending a column with the character count\n",
    "articles_df['character_count'] = articles_df['article'].apply(lambda x: character_counter(x))\n",
    "\n",
    "# Appending a column with the sentiment score\n",
    "articles_df['sentiment_analysis'] = articles_df['article'].apply(lambda x: sentiment_analysis(x))\n",
    "\n",
    "# Some more preprocessing of the text\n",
    "articles_df['article'] = articles_df['article'].apply(lambda x: lowercasing(x)) # Lowercasing\n",
    "articles_df['article'] = articles_df['article'].apply(lambda x: remove_punctuation(x)) # Removing punctuation\n",
    "\n",
    "# Count number of long words (>6 characters) in each body in articles_df and add to dataframe\n",
    "articles_df['long_words_count'] = articles_df['article'].apply(lambda x: long_words_counter(x))\n",
    "\n",
    "# Appends a column with the LIX score\n",
    "articles_df['lix'] = (articles_df['word_count']/articles_df['period_count']) + ((articles_df['long_words_count'])*100 / articles_df['word_count'])\n",
    "\n",
    "# Appends a column with the number of ci words\n",
    "articles_df['ci_words_count'] = articles_df['article'].apply(lambda x: count_ci_words(x))\n",
    "\n",
    "# Removing stopwords\n",
    "articles_df['article'] = articles_df['article'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the most common words to see if any needs to be added to the stopword list\n",
    "common_words = pd.Series(' '.join(articles_df['article']).split()).value_counts()[:20]\n",
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the entire labeled dataframe as a feather after the extra stopwords are removed\n",
    "\n",
    "extra_stopwords = ['så', 'kan'] # The chosen words to also be removed as stopwords\n",
    "articles_df['article'] = articles_df['article'].apply(lambda x: \" \".join(x for x in x.split() if x not in extra_stopwords)) # removing the extra stopwords\n",
    "\n",
    "articles_df.reset_index(inplace=True, drop=True) # Resetting the index\n",
    "articles_df.to_feather('data/articles_df_LABELLED_preprocessed.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw 114 articles_constructive = true and 114 articles_constructive = false without replacement\n",
    "articles_df_balanced = pd.concat([articles_df[articles_df['articles_constructive'] == False].sample(n=114, replace=False, random_state=42).reset_index(drop=True),articles_df[articles_df['articles_constructive'] == True].sample(n=114, replace=False, random_state=42).reset_index(drop=True)])\n",
    "\n",
    "# split articles_df_balanced into a balanced train validation and test set\n",
    "articles_df_train, articles_df_test = train_test_split(articles_df_balanced, test_size=0.21, random_state=42, stratify=articles_df_balanced['articles_constructive'])\n",
    "articles_df_train, articles_df_val = train_test_split(articles_df_train, test_size=0.23, random_state=42, stratify=articles_df_train['articles_constructive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df_train['articles_constructive'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df_val['articles_constructive'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df_test['articles_constructive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df_train.to_csv('data/train_new.csv', index=False)\n",
    "articles_df_val.to_csv('data/val_new.csv', index=False)\n",
    "articles_df_test.to_csv('data/test_new.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "withpip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c806f684894c34313ed67198043d86ce0c247a0773f2d84d25fc9b0dd277911"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
